\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Feature Design}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Removing Noisy Backgrounds}{1}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Three sample images from EMNIST, before filling the backgrounds (top) and after filling the backgrounds (bottom).}}{1}{figure.3}}
\newlabel{figurelabel}{{3}{1}{Three sample images from EMNIST, before filling the backgrounds (top) and after filling the backgrounds (bottom)}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Extracting the 'Largest' Digit}{1}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Three sample images from the MNIST dataset.}}{2}{figure.1}}
\newlabel{fig:test1}{{1}{2}{Three sample images from the MNIST dataset}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Three sample images from the EMNIST dataset.}}{2}{figure.2}}
\newlabel{fig:test2}{{2}{2}{Three sample images from the EMNIST dataset}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A sample image from EMNIST, superimposed by the geometric objects used to measure the size of each image using heuristics 1-4. Heuristic 1 is the top left, Huerustic 2 is the top right, Heuristic 3 is the bottom left, and Heuristic 4 is the bottom right.}}{2}{figure.4}}
\newlabel{figurelabel}{{4}{2}{A sample image from EMNIST, superimposed by the geometric objects used to measure the size of each image using heuristics 1-4. Heuristic 1 is the top left, Huerustic 2 is the top right, Heuristic 3 is the bottom left, and Heuristic 4 is the bottom right}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}Data Augmentation}{2}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A sample digit extracted from an EMNIST example after data augmentation. The original image yields a batch size of 21, with random rotations in the range [-20, 20].}}{2}{figure.5}}
\newlabel{figurelabel}{{5}{2}{A sample digit extracted from an EMNIST example after data augmentation. The original image yields a batch size of 21, with random rotations in the range [-20, 20]}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}ALGORITHMS}{2}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces One of the four CNN architectures we experimented with. The other three differ slightly in the kernel sizes, pooling sizes, and number of convolutional layers. Image modified from [6].}}{3}{figure.6}}
\newlabel{figurelabel}{{6}{3}{One of the four CNN architectures we experimented with. The other three differ slightly in the kernel sizes, pooling sizes, and number of convolutional layers. Image modified from [6]}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}METHODOLOGY}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Regularized Logistic Regression: Model Hyperparameters}{3}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Feedforward Neural Network: Model Hyperparameters}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Feedforward Neural Network: Learning Optimizations}{3}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Convolutional Neural Network: Hyperparameter Tuning}{3}{subsection.4.4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Hyperparameter Ranges Explored for CNN models}}{3}{table.1}}
\newlabel{my-label}{{I}{3}{Hyperparameter Ranges Explored for CNN models}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Constrained Hyperparameter Ranges}}{4}{table.2}}
\newlabel{my-label}{{II}{4}{Constrained Hyperparameter Ranges}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-E}CNN: Learning Optimization}{4}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-F}CNN: Aggregated Predictions}{4}{subsection.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Learning curves for training periods with $\eta = .0001$ and $\eta = .00005$, with early stopping. Note: training accuracy is lower than validation accuracy. This is because we used data augmentation, and the new randomly rotated images made the training data "harder" to learn than the validation data.}}{4}{figure.7}}
\newlabel{figurelabel}{{7}{4}{Learning curves for training periods with $\eta = .0001$ and $\eta = .00005$, with early stopping. Note: training accuracy is lower than validation accuracy. This is because we used data augmentation, and the new randomly rotated images made the training data "harder" to learn than the validation data}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}RESULTS}{4}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-A}Regularized Logistic Regression}{4}{subsection.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Best Logistic Regression Models, Trained with l1/l2 Loss}}{5}{table.3}}
\newlabel{my-}{{III}{5}{Best Logistic Regression Models, Trained with l1/l2 Loss}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-B}Feedforward Neural Network}{5}{subsection.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces FFNN Architectures}}{5}{table.4}}
\newlabel{my-label}{{IV}{5}{FFNN Architectures}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Validation Accuracies for FFNN Experiments}}{5}{table.5}}
\newlabel{my-label}{{V}{5}{Validation Accuracies for FFNN Experiments}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Best CNN Models for Different Data Augmentation Schemes}}{5}{table.6}}
\newlabel{my-label}{{VI}{5}{Best CNN Models for Different Data Augmentation Schemes}{table.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-C}Convolutional Neural Network}{5}{subsection.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces Highest performing CNN Models and Aggregations}}{5}{table.7}}
\newlabel{my-label}{{VII}{5}{Highest performing CNN Models and Aggregations}{table.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}DISCUSSION AND CONCLUSIONS}{6}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Statement of Contributions}{6}{section.7}}
\bibcite{c1}{1}
\bibcite{c2}{2}
\bibcite{c3}{3}
\bibcite{c4}{4}
\bibcite{c5}{5}
\bibcite{c6}{6}
\@writefile{toc}{\contentsline {section}{References}{7}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}APPENDIX}{8}{section.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Architecture 1: Three convolutional layers, 76,978 trainable parameters.}}{8}{figure.8}}
\newlabel{figurelabel}{{8}{8}{Architecture 1: Three convolutional layers, 76,978 trainable parameters}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Architecture 2: Four convolutional layers, 79,298 trainable parameters.}}{8}{figure.9}}
\newlabel{figurelabel}{{9}{8}{Architecture 2: Four convolutional layers, 79,298 trainable parameters}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Architecture 3: Four convolutional layers, 307,778 trainable parameters.}}{9}{figure.10}}
\newlabel{figurelabel}{{10}{9}{Architecture 3: Four convolutional layers, 307,778 trainable parameters}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Architecture 4: Six convolutional layers, 94,594 trainable parameters.}}{9}{figure.11}}
\newlabel{figurelabel}{{11}{9}{Architecture 4: Six convolutional layers, 94,594 trainable parameters}{figure.11}{}}
